:toc:               left
:toc-title:         MAC Inference Module
:toclevels:         2
:last-update-label!:
:docinfo:
:source-highlighter: coderay
:icons: font


= MAC Inference Module Documentation Reference

+++
This is the main class of an extension, is the entry point from which configurations, connection providers, operations and sources are going to be declared.
+++


== Configurations
---
[[config]]
=== Config

+++
Default configuration
+++

==== Parameters
[cols=".^20%,.^20%,.^35%,.^20%,^.^5%", options="header"]
|======================
| Name | Type | Description | Default Value | Required
|Name | String | The name for this configuration. Connectors reference the configuration with this name. | | *x*{nbsp}
| Inference Type a| String |  |  | *x*{nbsp}
| API Key a| String |  |  | *x*{nbsp}
| Virtual Key a| String |  |  +++Valid-for-portkey-only+++ | {nbsp}
| Model Name a| String |  |  +++gpt-3.5-turbo+++ | {nbsp}
| Max Tokens a| Number |  |  +++500+++ | {nbsp}
| Temperature a| Number |  |  +++0.9+++ | {nbsp}
| Top P a| Number |  |  +++0.9+++ | {nbsp}
| Ollama Base URL a| String |  |  +++http://localhost:11434/api+++ | {nbsp}
| Expiration Policy a| <<ExpirationPolicy>> |  +++Configures the minimum amount of time that a dynamic configuration instance can remain idle before the runtime considers it eligible for expiration. This does not mean that the platform will expire the instance at the exact moment that it becomes eligible. The runtime will actually purge the instances when it sees it fit.+++ |  | {nbsp}
|======================


==== Associated Operations
* <<Agent-define-prompt-template>> {nbsp}
* <<Chat-answer-prompt>> {nbsp}
* <<Chat-completions>> {nbsp}
* <<Tools-native-template>> {nbsp}



== Operations

[[Agent-define-prompt-template]]
=== Agent Define Prompt Template
`<mac-inference:agent-define-prompt-template>`

+++
Define a prompt template
+++

==== Parameters
[cols=".^20%,.^20%,.^35%,.^20%,^.^5%", options="header"]
|======================
| Name | Type | Description | Default Value | Required
| Configuration | String | The name of the configuration to use. | | *x*{nbsp}
| Template a| String |  |  | *x*{nbsp}
| Instructions a| String |  |  | *x*{nbsp}
| Data a| String |  |  +++#[payload]+++ | {nbsp}
| Streaming Strategy a| * <<repeatable-in-memory-stream>>
* <<repeatable-file-store-stream>>
* <<non-repeatable-stream>> |  +++Configure if repeatable streams should be used and their behaviour+++ |  | {nbsp}
| Target Variable a| String |  +++The name of a variable on which the operation's output will be placed+++ |  | {nbsp}
| Target Value a| String |  +++An expression that will be evaluated against the operation's output and the outcome of that expression will be stored in the target variable+++ |  +++#[payload]+++ | {nbsp}
|======================

==== Output
[cols=".^50%,.^50%"]
|======================
| *Type* a| Any
| *Attributes Type* a| <<LLMResponseAttributes>>
|======================

==== For Configurations.
* <<config>> {nbsp}



[[Chat-answer-prompt]]
=== Chat Answer Prompt
`<mac-inference:chat-answer-prompt>`

+++
Simple chat answer prompt
+++

==== Parameters
[cols=".^20%,.^20%,.^35%,.^20%,^.^5%", options="header"]
|======================
| Name | Type | Description | Default Value | Required
| Configuration | String | The name of the configuration to use. | | *x*{nbsp}
| Prompt a| String |  |  +++#[payload]+++ | {nbsp}
| Streaming Strategy a| * <<repeatable-in-memory-stream>>
* <<repeatable-file-store-stream>>
* <<non-repeatable-stream>> |  +++Configure if repeatable streams should be used and their behaviour+++ |  | {nbsp}
| Target Variable a| String |  +++The name of a variable on which the operation's output will be placed+++ |  | {nbsp}
| Target Value a| String |  +++An expression that will be evaluated against the operation's output and the outcome of that expression will be stored in the target variable+++ |  +++#[payload]+++ | {nbsp}
|======================

==== Output
[cols=".^50%,.^50%"]
|======================
| *Type* a| Any
| *Attributes Type* a| <<LLMResponseAttributes>>
|======================

==== For Configurations.
* <<config>> {nbsp}



[[Chat-completions]]
=== Chat Completions
`<mac-inference:chat-completions>`

+++
Chat completions by messages array including system, users messages i.e. conversation history
+++

==== Parameters
[cols=".^20%,.^20%,.^35%,.^20%,^.^5%", options="header"]
|======================
| Name | Type | Description | Default Value | Required
| Configuration | String | The name of the configuration to use. | | *x*{nbsp}
| Messages a| Binary |  |  +++#[payload]+++ | {nbsp}
| Streaming Strategy a| * <<repeatable-in-memory-stream>>
* <<repeatable-file-store-stream>>
* <<non-repeatable-stream>> |  +++Configure if repeatable streams should be used and their behaviour+++ |  | {nbsp}
| Target Variable a| String |  +++The name of a variable on which the operation's output will be placed+++ |  | {nbsp}
| Target Value a| String |  +++An expression that will be evaluated against the operation's output and the outcome of that expression will be stored in the target variable+++ |  +++#[payload]+++ | {nbsp}
|======================

==== Output
[cols=".^50%,.^50%"]
|======================
| *Type* a| Any
| *Attributes Type* a| <<LLMResponseAttributes>>
|======================

==== For Configurations.
* <<config>> {nbsp}



[[Tools-native-template]]
=== Tools Native Template
`<mac-inference:tools-native-template>`

+++
Define a tools template
+++

==== Parameters
[cols=".^20%,.^20%,.^35%,.^20%,^.^5%", options="header"]
|======================
| Name | Type | Description | Default Value | Required
| Configuration | String | The name of the configuration to use. | | *x*{nbsp}
| Template a| String |  |  | *x*{nbsp}
| Instructions a| String |  |  | *x*{nbsp}
| Data a| String |  |  +++#[payload]+++ | {nbsp}
| Tools a| Binary |  |  | *x*{nbsp}
| Streaming Strategy a| * <<repeatable-in-memory-stream>>
* <<repeatable-file-store-stream>>
* <<non-repeatable-stream>> |  +++Configure if repeatable streams should be used and their behaviour+++ |  | {nbsp}
| Target Variable a| String |  +++The name of a variable on which the operation's output will be placed+++ |  | {nbsp}
| Target Value a| String |  +++An expression that will be evaluated against the operation's output and the outcome of that expression will be stored in the target variable+++ |  +++#[payload]+++ | {nbsp}
|======================

==== Output
[cols=".^50%,.^50%"]
|======================
| *Type* a| Any
| *Attributes Type* a| <<LLMResponseAttributes>>
|======================

==== For Configurations.
* <<config>> {nbsp}




== Types
[[ExpirationPolicy]]
=== Expiration Policy

[cols=".^20%,.^25%,.^30%,.^15%,.^10%", options="header"]
|======================
| Field | Type | Description | Default Value | Required
| Max Idle Time a| Number | A scalar time value for the maximum amount of time a dynamic configuration instance should be allowed to be idle before it's considered eligible for expiration |  | 
| Time Unit a| Enumeration, one of:

** NANOSECONDS
** MICROSECONDS
** MILLISECONDS
** SECONDS
** MINUTES
** HOURS
** DAYS | A time unit that qualifies the maxIdleTime attribute |  | 
|======================

[[LLMResponseAttributes]]
=== LLM Response Attributes

[cols=".^20%,.^25%,.^30%,.^15%,.^10%", options="header"]
|======================
| Field | Type | Description | Default Value | Required
| Additional Attributes a| Object |  |  | 
| Token Usage a| <<TokenUsage>> |  |  | 
|======================

[[TokenUsage]]
=== Token Usage

[cols=".^20%,.^25%,.^30%,.^15%,.^10%", options="header"]
|======================
| Field | Type | Description | Default Value | Required
| Input Count a| Number |  |  | 
| Output Count a| Number |  |  | 
| Total Count a| Number |  |  | 
|======================

[[repeatable-in-memory-stream]]
=== Repeatable In Memory Stream

[cols=".^20%,.^25%,.^30%,.^15%,.^10%", options="header"]
|======================
| Field | Type | Description | Default Value | Required
| Initial Buffer Size a| Number | This is the amount of memory that will be allocated in order to consume the stream and provide random access to it. If the stream contains more data than can be fit into this buffer, then it will be expanded by according to the bufferSizeIncrement attribute, with an upper limit of maxInMemorySize. |  | 
| Buffer Size Increment a| Number | This is by how much will be buffer size by expanded if it exceeds its initial size. Setting a value of zero or lower will mean that the buffer should not expand, meaning that a STREAM_MAXIMUM_SIZE_EXCEEDED error will be raised when the buffer gets full. |  | 
| Max Buffer Size a| Number | This is the maximum amount of memory that will be used. If more than that is used then a STREAM_MAXIMUM_SIZE_EXCEEDED error will be raised. A value lower or equal to zero means no limit. |  | 
| Buffer Unit a| Enumeration, one of:

** BYTE
** KB
** MB
** GB | The unit in which all these attributes are expressed |  | 
|======================

[[repeatable-file-store-stream]]
=== Repeatable File Store Stream

[cols=".^20%,.^25%,.^30%,.^15%,.^10%", options="header"]
|======================
| Field | Type | Description | Default Value | Required
| In Memory Size a| Number | Defines the maximum memory that the stream should use to keep data in memory. If more than that is consumed then it will start to buffer the content on disk. |  | 
| Buffer Unit a| Enumeration, one of:

** BYTE
** KB
** MB
** GB | The unit in which maxInMemorySize is expressed |  | 
|======================

