<?xml version="1.0" encoding="UTF-8" standalone="no"?><mule xmlns="http://www.mulesoft.org/schema/mule/core" xmlns:doc="http://www.mulesoft.org/schema/mule/documentation" xmlns:ee="http://www.mulesoft.org/schema/mule/ee/core" xmlns:mac-inference="http://www.mulesoft.org/schema/mule/mac-inference" xmlns:munit="http://www.mulesoft.org/schema/mule/munit" xmlns:munit-tools="http://www.mulesoft.org/schema/mule/munit-tools" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="         http://www.mulesoft.org/schema/mule/core http://www.mulesoft.org/schema/mule/core/current/mule.xsd         http://www.mulesoft.org/schema/mule/munit http://www.mulesoft.org/schema/mule/munit/current/mule-munit.xsd         http://www.mulesoft.org/schema/mule/munit-tools http://www.mulesoft.org/schema/mule/munit-tools/current/mule-munit-tools.xsd         http://www.mulesoft.org/schema/mule/mac-inference http://www.mulesoft.org/schema/mule/mac-inference/current/mule-mac-inference.xsd         http://www.mulesoft.org/schema/mule/ee/core http://www.mulesoft.org/schema/mule/ee/core/current/mule-ee.xsd">

	<munit:config name="tools-native-template.xml">
		<munit:parameterizations>
			<munit:parameterization name="config-openai">
				<munit:parameters>
					<munit:parameter propertyName="config" value="OpenAIConfig"/>
					<munit:parameter propertyName="llmModel" value="${openai.llmModel}"/>
					<munit:parameter propertyName="inputCount" value="412"/>
				</munit:parameters>
			</munit:parameterization>
			<munit:parameterization name="config-mistralai">
				<munit:parameters>
					<munit:parameter propertyName="config" value="MistralAIConfig"/>
					<munit:parameter propertyName="llmModel" value="${mistral.llmModel}"/>
					<munit:parameter propertyName="inputCount" value="634"/>
				</munit:parameters>
			</munit:parameterization>
			<munit:parameterization name="config-openrouter" >
				<munit:parameters >
					<munit:parameter propertyName="config" value="OpenrouterConfig" />
					<munit:parameter propertyName="llmModel" value="${openrouter.llmModel}" />
					<munit:parameter propertyName="inputCount" value="632" />
				</munit:parameters>
			</munit:parameterization>
			<munit:parameterization name="config-openai-compatible" >
				<munit:parameters >
					<munit:parameter propertyName="config" value="OpenAICompatibleConfig" />
					<munit:parameter propertyName="llmModel" value="${openai-compatible.llmModel}" />
					<munit:parameter propertyName="inputCount" value="412" />
				</munit:parameters>
			</munit:parameterization>
			<munit:parameterization name="config-huggingface" >
				<munit:parameters >
					<munit:parameter propertyName="config" value="HuggingFaceConfig" />
					<munit:parameter propertyName="llmModel" value="${huggingface.llmModel}" />
					<munit:parameter propertyName="inputCount" value="757" />
				</munit:parameters>
			</munit:parameterization>
			<munit:parameterization name="config-groq" >
				<munit:parameters >
					<munit:parameter propertyName="config" value="GroqConfig" />
					<munit:parameter propertyName="llmModel" value="${groq.llmModel}" />
					<munit:parameter propertyName="inputCount" value="1595" />
				</munit:parameters>
			</munit:parameterization>
			<!--<munit:parameterization name="config-ibm-watson" >
				<munit:parameters >
					<munit:parameter propertyName="config" value="IBMWatsonConfig" />
					<munit:parameter propertyName="llmModel" value="${ibm-watson.llmModel}" />
					<munit:parameter propertyName="inputCount" value="123" />
				</munit:parameters>
			</munit:parameterization> -->
			<munit:parameterization name="config-ollama" >
				<munit:parameters >
					<munit:parameter propertyName="config" value="OllamaConfig" />
					<munit:parameter propertyName="llmModel" value="${ollama.llmModel}" />
					<munit:parameter propertyName="inputCount" value="26" />
				</munit:parameters>
			</munit:parameterization>
			<munit:parameterization name="config-github" >
				<munit:parameters >
					<munit:parameter propertyName="config" value="GithubConfig" />
					<munit:parameter propertyName="llmModel" value="${github.llmModel}" />
					<munit:parameter propertyName="model" value="${github.model}" />
					<munit:parameter propertyName="inputCount" value="412" />
				</munit:parameters>
			</munit:parameterization>
			<munit:parameterization name="config-cerebras" >
				<munit:parameters >
					<munit:parameter propertyName="config" value="CerebrasConfig" />
					<munit:parameter propertyName="llmModel" value="${cerebras.llmModel}" />
					<munit:parameter propertyName="inputCount" value="1175" />
				</munit:parameters>
			</munit:parameterization>
			<munit:parameterization name="config-nvidia" >
				<munit:parameters >
					<munit:parameter propertyName="config" value="NvidiaConfig" />
					<munit:parameter propertyName="llmModel" value="${nvidia.llmModel}" />
					<munit:parameter propertyName="inputCount" value="1091" />
				</munit:parameters>
			</munit:parameterization>
			<munit:parameterization name="config-xai" >
				<munit:parameters >
					<munit:parameter propertyName="config" value="XaiConfig" />
					<munit:parameter propertyName="llmModel" value="${xai.llmModel}" />
					<munit:parameter propertyName="inputCount" value="731" />
				</munit:parameters>
			</munit:parameterization>
			<munit:parameterization name="config-anthropic" >
				<munit:parameters >
					<munit:parameter propertyName="config" value="AnthropicConfig" />
					<munit:parameter propertyName="llmModel" value="${anthropic.llmModel}" />
					<munit:parameter propertyName="inputCount" value="993" />
				</munit:parameters>
			</munit:parameterization>
			<munit:parameterization name="config-ai21labs" >
				<munit:parameters >
					<munit:parameter propertyName="config" value="Ai21labsConfig" />
					<munit:parameter propertyName="llmModel" value="${ai21labs.llmModel}" />
					<munit:parameter propertyName="inputCount" value="774" />
				</munit:parameters> 
			</munit:parameterization>
			<munit:parameterization name="config-cohere" >
				<munit:parameters >
					<munit:parameter propertyName="config" value="CohereConfig" />
					<munit:parameter propertyName="llmModel" value="${cohere.llmModel}" />
					<munit:parameter propertyName="inputCount" value="354" />
				</munit:parameters>
			</munit:parameterization>
			<!-- <munit:parameterization name="config-xinference" >
				<munit:parameters >
					<munit:parameter propertyName="config" value="XinferenceConfig" />
					<munit:parameter propertyName="llmModel" value="${xinference.llmModel}" />
					<munit:parameter propertyName="inputCount" value="20" />
				</munit:parameters>
			</munit:parameterization> -->
			<munit:parameterization name="config-zhipu" >
				<munit:parameters >
					<munit:parameter propertyName="config" value="ZhipuConfig" />
					<munit:parameter propertyName="llmModel" value="${zhipu.llmModel}" />
					<munit:parameter propertyName="inputCount" value="735" />
				</munit:parameters>
			</munit:parameterization>
			<!-- <munit:parameterization name="config-portkey" >
				<munit:parameters >
					<munit:parameter propertyName="config" value="PortkeyConfig" />
					<munit:parameter propertyName="llmModel" value="${portkey.llmModel}" />
					<munit:parameter propertyName="inputCount" value="17" />
				</munit:parameters>
			</munit:parameterization> -->
			<munit:parameterization name="config-llmapi" >
				<munit:parameters >
					<munit:parameter propertyName="config" value="LlmApiConfig" />
					<munit:parameter propertyName="llmModel" value="${llmapi.mcpToolModel}" />
					<munit:parameter propertyName="inputCount" value="28" />
				</munit:parameters>
			</munit:parameterization>
		</munit:parameterizations>
	</munit:config>

	<munit:test description="Test" doc:id="da368b58-d280-4c01-975a-f443d8038e53" name="MCP_TOOLING_OPERATION-Test">
		<munit:execution>
			<flow-ref doc:id="857e9da2-0d1d-45ca-bd2f-3909efff3841" doc:name="Flow-ref to TOOLS_NATIVE_TEMPLATE_OPERATION" name="mcp_tooling"/>
			<logger doc:id="afa15bb1-3ba6-430d-b3ed-81103128695d" doc:name="Logger" level="INFO" message="#[payload]"/>
		</munit:execution>
		<munit:validation>
			<!-- Fixed: Use payload.payload.tools -->
			<munit-tools:assert-that doc:id="034ef6d8-64a0-4be0-b441-7d80c059f748" doc:name="payload.tools" expression="#[(sizeOf((payload.payload.tools default [])) == 0) as Boolean]" is="#[MunitTools::equalTo(false)]" message="The tools array should not be empty"/>
			<!-- Fixed: Use payload.payload.tools -->
			<munit-tools:assert-that doc:name="payload.toolExecutionReport" doc:id="701a8e8c-1286-4ce5-a050-53f5c22fc480" message="The tools array should contain a tool exeuction report" expression="#[(sizeOf(payload.payload.toolsExecutionReport default []) == 0) as Boolean]" is="#[MunitTools::equalTo(false)]" />
			<munit-tools:assert-that doc:id="cb23f789-4c28-446c-9ee1-343c443d1636" doc:name="get_current_temperature check" expression="#[(sizeOf((payload.payload.tools default []) filter (tool) -&gt; (tool.function.name default '') == 'get_inventory') &gt; 0) as Boolean]" is="#[MunitTools::equalTo(true)]" message="The tools array should contain an item with function.name 'get_inventory'"/>
			<!-- Fixed: Use payload.payload.tools -->
			<munit-tools:assert-equals actual="#[attributes.tokenUsage.inputCount as String]" doc:id="8a3d65aa-b548-44cf-a627-82c7d0580659" doc:name="Input Token" expected="${inputCount}" message="Incorrect Input Token"/>
			<munit-tools:assert-equals actual="#[attributes.additionalAttributes.model]" doc:id="521e3135-5c80-4521-abdd-11877c8e8189" doc:name="model Info" expected="${llmModel}" message="Incorrect Model Info"/>
		</munit:validation>
	</munit:test>

	<sub-flow doc:id="71465f76-1597-41ec-bcb7-3d4aa45c3cac" name="mcp_tooling">
		<set-variable doc:id="7edeecec-4d47-4bfe-a699-23987b60ac14" doc:name="Set Variable" value='#[%dw 2.0             &#10;output application/json&#10;---&#10;{&#10;    "template": "You are an helpful assistant",&#10;    "instructions":"Answer the request with politeness.",&#10;    "dataset": "Check Inventory for MULETEST0"&#10;&#10;}]' variableName="testPayload"/>
		<mac-inference:mcp-tools-native-template doc:name="[MCP] Tooling" doc:id="6783c672-bc72-49c7-bf3a-3f3379e3c9a9" config-ref="${config}">
			<mac-inference:template ><![CDATA[#[vars.testPayload.template]]]></mac-inference:template>
			<mac-inference:instructions ><![CDATA[#[vars.testPayload.instructions]]]></mac-inference:instructions>
			<mac-inference:data ><![CDATA[#[vars.testPayload.dataset]]]></mac-inference:data>
		</mac-inference:mcp-tools-native-template>
		<ee:transform doc:id="8eda33bd-db2f-412a-b448-dc633d326a39" doc:name="Transform Message">
			<ee:message>
				<ee:set-payload><![CDATA[%dw 2.0
                output application/json
                ---
                {
                    payload: payload,
                    attributes: attributes
                }]]></ee:set-payload>
			</ee:message>
		</ee:transform>
	</sub-flow>
</mule>