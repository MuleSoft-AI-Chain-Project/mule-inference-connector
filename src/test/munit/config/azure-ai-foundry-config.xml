<?xml version="1.0" encoding="UTF-8"?>

<mule xmlns:ms-inference="http://www.mulesoft.org/schema/mule/ms-inference"
      xmlns:http="http://www.mulesoft.org/schema/mule/http"
      xmlns="http://www.mulesoft.org/schema/mule/core"
      xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
      xmlns:doc="http://www.mulesoft.org/schema/mule/documentation"
      xsi:schemaLocation="
        http://www.mulesoft.org/schema/mule/core http://www.mulesoft.org/schema/mule/core/current/mule.xsd
        http://www.mulesoft.org/schema/mule/ms-inference http://www.mulesoft.org/schema/mule/ms-inference/current/mule-ms-inference.xsd
        http://www.mulesoft.org/schema/mule/http http://www.mulesoft.org/schema/mule/http/current/mule-http.xsd">

    <configuration-properties file="automation-credentials.properties"/>

    <!-- Text Generation Configuration -->
    <ms-inference:text-generation-config name="azureAiFoundryConfig" doc:name="MuleSoft Inference Text generation config" doc:id="9d6a6703-45e0-4cba-92e9-b479535128e3" >
        <ms-inference:azure-ai-foundry-connection apiKey="${azure-ai-foundry.apiKey}" azureModelName="${azure-ai-foundry.llmModel}"
                                                   azureAIFoundryApiVersion="${azure-ai-foundry.apiVersion}"
                                                   azureAIFoundryResourceName="${azure-ai-foundry.resource}"
                                                   maxTokens="2000" >
        </ms-inference:azure-ai-foundry-connection>
    </ms-inference:text-generation-config>

    <!-- Text Generation Configuration negative test-->
    <ms-inference:text-generation-config name="azureAiFoundryInvalidConfig" doc:name="MuleSoft Inference Text generation config" doc:id="8a9339fa-da4b-46e7-9f3c-926ebe705fad" >
        <ms-inference:azure-ai-foundry-connection azureModelName="${azure-ai-foundry.llmModel}"
                                                  azureAIFoundryApiVersion="${azure-ai-foundry.apiVersion}"
                                                  azureAIFoundryResourceName="${azure-ai-foundry.resource}" apiKey="${azure-ai-foundry.apiKey}" >
            <ms-inference:custom-headers >
                <ms-inference:default-header key="api-key" value="#[vars.apikey]" />
            </ms-inference:custom-headers>
        </ms-inference:azure-ai-foundry-connection>
    </ms-inference:text-generation-config>

    <!-- Vision Configuration -->
    <ms-inference:vision-config name="AzureAiFoundryVisionConfig" doc:name="MuleSoft Inference Vision config" doc:id="13da78c8-3d61-468a-8fd0-629dda8c57ee" >
        <ms-inference:azure-ai-foundry-vision-connection apiKey="${azure-ai-foundry.apiKey}" azureAIFoundryModelName="${azure-ai-foundry.visionModel}"
                                                          azureAIFoundryApiVersion="${azure-ai-foundry.apiVersion}"
                                                          azureAIFoundryResourceName="${azure-ai-foundry.resource}"
                                                          maxTokens="2000" />
    </ms-inference:vision-config>

</mule> 