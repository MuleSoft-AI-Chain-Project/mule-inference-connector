<?xml version="1.0" encoding="UTF-8"?>

<mule xmlns:mac-inference="http://www.mulesoft.org/schema/mule/mac-inference"
      xmlns:tls="http://www.mulesoft.org/schema/mule/tls"
      xmlns:http="http://www.mulesoft.org/schema/mule/http"
      xmlns="http://www.mulesoft.org/schema/mule/core"
      xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
      xmlns:doc="http://www.mulesoft.org/schema/mule/documentation"
      xsi:schemaLocation="
        http://www.mulesoft.org/schema/mule/core http://www.mulesoft.org/schema/mule/core/current/mule.xsd
        http://www.mulesoft.org/schema/mule/mac-inference http://www.mulesoft.org/schema/mule/mac-inference/current/mule-mac-inference.xsd
        http://www.mulesoft.org/schema/mule/http http://www.mulesoft.org/schema/mule/http/current/mule-http.xsd
        http://www.mulesoft.org/schema/mule/tls http://www.mulesoft.org/schema/mule/tls/current/mule-tls.xsd">

    <configuration-properties file="automation-credentials.properties"/>

    <mac-inference:text-generation-config name="OpenAIConfig" doc:name="Open AI Text generation config" doc:id="1ef66d01-d3ec-442a-bf61-99919d73f97e" >
        <mac-inference:openai-connection apiKey="${openai.apiKey}" openAIModelName="${openai.llmModel}" timeout="60000">
            <mac-inference:mcp-sse-servers >
                <mac-inference:mcp-sse-server key="ERP Server" value="http://mcp-server-demo-b2jb0y.1d6nel.usa-e1.cloudhub.io" />
                <mac-inference:mcp-sse-server key="CRM Server" value="http://mcp-server-demo-crm-b2jb0y.1d6nel.usa-e1.cloudhub.io" />
            </mac-inference:mcp-sse-servers>
        </mac-inference:openai-connection>
    </mac-inference:text-generation-config>

    <mac-inference:text-generation-config name="MistralAIConfig" doc:name="Mistral AI Text generation config" doc:id="1ef66d01-d3ec-442a-bf61-99919d73f97e" >
        <mac-inference:mistralai-connection apiKey="${mistral.apiKey}" mistralAIModelName="${mistral.llmModel}" timeout="60000">
            <mac-inference:mcp-sse-servers >
                <mac-inference:mcp-sse-server key="ERP Server" value="http://mcp-server-demo-b2jb0y.1d6nel.usa-e1.cloudhub.io" />
                <mac-inference:mcp-sse-server key="CRM Server" value="http://mcp-server-demo-crm-b2jb0y.1d6nel.usa-e1.cloudhub.io" />
            </mac-inference:mcp-sse-servers>
        </mac-inference:mistralai-connection>
    </mac-inference:text-generation-config>

    <mac-inference:text-generation-config name="OpenrouterConfig" doc:name="Mistral AI Text generation config" doc:id="1ef66d01-d3ec-442a-bf61-99919d73f97e" >
        <mac-inference:openrouter-connection apiKey="${openrouter.apiKey}" openRouterModelName="${openrouter.llmModel}" timeout="60000">
            <mac-inference:mcp-sse-servers >
                <mac-inference:mcp-sse-server key="ERP Server" value="http://mcp-server-demo-b2jb0y.1d6nel.usa-e1.cloudhub.io" />
                <mac-inference:mcp-sse-server key="CRM Server" value="http://mcp-server-demo-crm-b2jb0y.1d6nel.usa-e1.cloudhub.io" />
            </mac-inference:mcp-sse-servers>
        </mac-inference:openrouter-connection>
    </mac-inference:text-generation-config>

    <mac-inference:moderation-config name="OpenAIModeration" doc:name="MuleSoft Inference Moderation config" doc:id="8bd9c1fe-3176-4319-9d91-090e4e6da3cc" >
        <mac-inference:openai-moderation-connection apiKey="${openai.apiKey}" openAIModelName="${openai.moderation}"/>
    </mac-inference:moderation-config>

    <mac-inference:moderation-config name="MistralAIModeration" doc:name="MuleSoft Inference Moderation config" doc:id="81c94800-d1ef-417f-a084-3052a907abc6" >
        <mac-inference:mistralai-moderation-connection apiKey="${mistral.apiKey}" mistralAIModelName="${mistral.moderation}"/>
    </mac-inference:moderation-config>

    <mac-inference:image-generation-config name="OpenAIImageGen" doc:name="MuleSoft Inference Image generation config" doc:id="aba51427-1dd3-4915-a411-8fe6543ee6ac" >
        <mac-inference:openai-image-connection apiKey="${openai.apiKey}" openAIModelName="${openai.imageGenModel}" />
    </mac-inference:image-generation-config>

    <mac-inference:vision-config name="OpenAIVision" doc:name="MuleSoft Inference Vision config" doc:id="797661b2-a4ac-493d-8550-45d05d03da17" >
        <mac-inference:openai-vision-connection apiKey="${openai.apiKey}" openAIModelName="${openai.visionModel}" />
    </mac-inference:vision-config>

    <mac-inference:vision-config name="MistralAIVision" doc:name="MuleSoft Inference Vision config" doc:id="2ed49ebd-4050-4b0b-acc1-aba75096c78a" >
        <mac-inference:mistralai-vision-connection apiKey="${mistral.apiKey}" mistralAIModelName="${mistral.visionModel}" />
    </mac-inference:vision-config>

    <mac-inference:vision-config name="OpenrouterVision" doc:name="MuleSoft Inference Vision config" doc:id="43158d4f-b08f-4ddc-8ff1-9865c406316e" >
        <mac-inference:openrouter-vision-connection apiKey="${openrouter.apiKey}" openRouterModelName="${openrouter.visionModel}" />
    </mac-inference:vision-config>

	<mac-inference:vision-config name="AzureAIFoundryVision" doc:name="MuleSoft Inference Vision config" doc:id="ebe6db24-f8c1-4e4f-b45c-bf9081c39a3f" >
		<mac-inference:vision-connection inferenceType="${azure-ai-foundry.inferenceType}" apiKey="${azure-ai-foundry.apiKey}" modelName="${azure-ai-foundry.visionModel}" azureAIFoundryApiVersion="${azure-ai-foundry.apiVersion}" azureAIFoundryResourceName="${azure-ai-foundry.resource}" />
	</mac-inference:vision-config>
	<mac-inference:text-generation-config name="azureAiFoundryConfig" doc:name="MuleSoft Inference Text generation config" doc:id="9d6a6703-45e0-4cba-92e9-b479535128e3" >
		<mac-inference:llm-connection inferenceType="${azure-ai-foundry.inferenceType}" apiKey="${azure-ai-foundry.apiKey}" modelName="${azure-ai-foundry.llmModel}" azureAIFoundryApiVersion="${azure-ai-foundry.apiVersion}" azureAIFoundryResourceName="${azure-ai-foundry.resource}">
            <mac-inference:mcp-sse-servers >
                <mac-inference:mcp-sse-server key="ERP Server" value="http://mcp-server-demo-b2jb0y.1d6nel.usa-e1.cloudhub.io" />
                <mac-inference:mcp-sse-server key="CRM Server" value="http://mcp-server-demo-crm-b2jb0y.1d6nel.usa-e1.cloudhub.io" />
            </mac-inference:mcp-sse-servers>
		</mac-inference:llm-connection>
	</mac-inference:text-generation-config>
	<mac-inference:text-generation-config name="deepinfraConfig" doc:name="MuleSoft Inference Text generation config" doc:id="1dd19de4-bdc1-4f11-88d6-aa23a9bc983b" >
		<mac-inference:llm-connection inferenceType="${deepinfra.inferenceType}" apiKey="${deepinfra.apiKey}" modelName="${deepinfra.llmModel}">
            <mac-inference:mcp-sse-servers >
                <mac-inference:mcp-sse-server key="ERP Server" value="http://mcp-server-demo-b2jb0y.1d6nel.usa-e1.cloudhub.io" />
                <mac-inference:mcp-sse-server key="CRM Server" value="http://mcp-server-demo-crm-b2jb0y.1d6nel.usa-e1.cloudhub.io" />
            </mac-inference:mcp-sse-servers>
		</mac-inference:llm-connection>
	</mac-inference:text-generation-config>
	<mac-inference:text-generation-config name="deepseekConfig" doc:name="MuleSoft Inference Text generation config" doc:id="dec55a3a-69c2-4a86-9063-d48146f56f37" >
		<mac-inference:llm-connection inferenceType="${deepseek.inferenceType}" apiKey="${deepseek.apiKey}" modelName="${deepseek.llmModel}">
            <mac-inference:mcp-sse-servers >
                <mac-inference:mcp-sse-server key="ERP Server" value="http://mcp-server-demo-b2jb0y.1d6nel.usa-e1.cloudhub.io" />
                <mac-inference:mcp-sse-server key="CRM Server" value="http://mcp-server-demo-crm-b2jb0y.1d6nel.usa-e1.cloudhub.io" />
            </mac-inference:mcp-sse-servers>
		</mac-inference:llm-connection>
	</mac-inference:text-generation-config>
	<mac-inference:text-generation-config name="togetherConfig" doc:name="MuleSoft Inference Text generation config" doc:id="adeed5a3-0df6-452a-a283-c0266d0f7977" >
		<mac-inference:llm-connection inferenceType="${together.inferenceType}" apiKey="${together.apiKey}" modelName="${together.llmModel}">
            <mac-inference:mcp-sse-servers >
                <mac-inference:mcp-sse-server key="ERP Server" value="http://mcp-server-demo-b2jb0y.1d6nel.usa-e1.cloudhub.io" />
                <mac-inference:mcp-sse-server key="CRM Server" value="http://mcp-server-demo-crm-b2jb0y.1d6nel.usa-e1.cloudhub.io" />
            </mac-inference:mcp-sse-servers>
		</mac-inference:llm-connection>
	</mac-inference:text-generation-config>
	<mac-inference:text-generation-config name="fireworksConfig" doc:name="MuleSoft Inference Text generation config" doc:id="7257fcc9-54a5-41c9-87c7-5f3950fd16bf" >
		<mac-inference:llm-connection inferenceType="${fireworks.inferenceType}" apiKey="${fireworks.apiKey}" modelName="${fireworks.llmModel}">
            <mac-inference:mcp-sse-servers >
                <mac-inference:mcp-sse-server key="ERP Server" value="http://mcp-server-demo-b2jb0y.1d6nel.usa-e1.cloudhub.io" />
                <mac-inference:mcp-sse-server key="CRM Server" value="http://mcp-server-demo-crm-b2jb0y.1d6nel.usa-e1.cloudhub.io" />
            </mac-inference:mcp-sse-servers>
		</mac-inference:llm-connection>
	</mac-inference:text-generation-config>
</mule>