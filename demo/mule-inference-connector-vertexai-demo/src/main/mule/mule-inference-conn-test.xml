<?xml version="1.0" encoding="UTF-8"?>

<mule xmlns:file="http://www.mulesoft.org/schema/mule/file" xmlns:ee="http://www.mulesoft.org/schema/mule/ee/core"
	xmlns:mac-inference="http://www.mulesoft.org/schema/mule/mac-inference"
	xmlns:http="http://www.mulesoft.org/schema/mule/http" xmlns="http://www.mulesoft.org/schema/mule/core" xmlns:doc="http://www.mulesoft.org/schema/mule/documentation" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mulesoft.org/schema/mule/core http://www.mulesoft.org/schema/mule/core/current/mule.xsd
http://www.mulesoft.org/schema/mule/http http://www.mulesoft.org/schema/mule/http/current/mule-http.xsd
http://www.mulesoft.org/schema/mule/mac-inference http://www.mulesoft.org/schema/mule/mac-inference/current/mule-mac-inference.xsd
http://www.mulesoft.org/schema/mule/ee/core http://www.mulesoft.org/schema/mule/ee/core/current/mule-ee.xsd
http://www.mulesoft.org/schema/mule/file http://www.mulesoft.org/schema/mule/file/current/mule-file.xsd">
	<http:listener-config name="HTTP_Listener_config" doc:name="HTTP Listener config" doc:id="336c0171-2401-4ebd-bfbe-638579321a0b" >
		<http:listener-connection host="0.0.0.0" port="8081" />
	</http:listener-config>
	<configuration-properties doc:name="Configuration properties" doc:id="4e72178c-df12-42c1-bb95-13de59628c8e" file="llm.properties" />
	<mac-inference:text-generation-config name="MuleSoft_Inference_Text_generation_config" doc:name="MuleSoft Inference Text generation config" doc:id="74d31f3d-2a1a-4e5f-bbe6-14fd656d4d46" >
		<mac-inference:llm-connection inferenceType="${llm}" apiKey="${api.key}" modelName="${model.name}" vertexAIProjectId="${vertexAIProjectId}" vertexAILocationId="${vertexAILocationId}" vertexAIServiceAccountKey="#[mule.home ++ '/apps/' ++ app.name ++ '/gcp/service-account.json']"/>
	</mac-inference:text-generation-config>
	<mac-inference:vision-config name="MuleSoft_Inference_Vision_config" doc:name="MuleSoft Inference Vision config" doc:id="81b803f6-954a-4b71-a41b-6fa6472c59bc" >
		<mac-inference:vision-connection inferenceType="${llm}" apiKey="${api.key}" modelName="${model.name}" vertexAILocationId="${vertexAILocationId}" vertexAIProjectId="${vertexAIProjectId}" vertexAIServiceAccountKey="#[mule.home ++ '/apps/' ++ app.name ++ '/gcp/service-account.json']"/>
	</mac-inference:vision-config>
	<file:config name="File_Config" doc:name="File Config" doc:id="206ea059-e574-4ab1-8a8e-2e6130811238" />
	<flow name="mule-inference-conn-testFlow" doc:id="0c399970-82e6-4060-b74b-a9351a92e690" >
		<http:listener doc:name="Listener" doc:id="28c1e0f2-5a58-4e44-8801-f5d8c219f895" config-ref="HTTP_Listener_config" path="/inference"/>
		
		<logger level="INFO" message="GOOGLE_APPLICATION_CREDENTIALS = #[p('GOOGLE_APPLICATION_CREDENTIALS')]"/>
		
		<choice doc:name="Choice" doc:id="32aef616-e2f0-4cbe-8180-f0e1af8a450a" >
			<when expression='#[attributes.queryParams.operation == "tools"]'>
				<mac-inference:tools-native-template doc:name="Tools native template" doc:id="ca897da5-ad26-4dd1-805e-c9649ae73123" config-ref="MuleSoft_Inference_Text_generation_config">
			<mac-inference:template><![CDATA[#[payload.template]]]></mac-inference:template>
			<mac-inference:instructions><![CDATA[#[payload.instructions]]]></mac-inference:instructions>
			<mac-inference:data><![CDATA[#[payload.data]]]></mac-inference:data>
			<mac-inference:tools><![CDATA[#[payload.tools]]]></mac-inference:tools>
		</mac-inference:tools-native-template>
			</when>
			<when expression='#[attributes.queryParams.operation == "template"]'>
				<mac-inference:agent-define-prompt-template doc:name="Agent define prompt template" doc:id="9a88b67e-3051-4757-a7db-b62b9a161a28" config-ref="MuleSoft_Inference_Text_generation_config">
			<mac-inference:template><![CDATA[#[payload.template]]]></mac-inference:template>
			<mac-inference:instructions><![CDATA[#[payload.instructions]]]></mac-inference:instructions>
			<mac-inference:data><![CDATA[#[payload.data]]]></mac-inference:data>
		</mac-inference:agent-define-prompt-template>
			</when>
			<when expression='#[attributes.queryParams.operation == "prompt"]' >
				<mac-inference:chat-answer-prompt doc:name="[Chat] Answer Prompt" doc:id="9a4638bd-ad12-4f88-8fb8-b8e9d7011841" config-ref="MuleSoft_Inference_Text_generation_config">
					<mac-inference:prompt ><![CDATA[#[payload.prompt]]]></mac-inference:prompt>
				</mac-inference:chat-answer-prompt>
			</when>
			<when expression='#[attributes.queryParams.operation == "readImage"]' >
				<mac-inference:read-image doc:name="[Image] Read by (Url or Base64)" doc:id="edbbad91-0f9a-4776-a604-9cbfea0c54dd" config-ref="MuleSoft_Inference_Vision_config">
					<mac-inference:prompt ><![CDATA[#[payload.prompt]]]></mac-inference:prompt>
					<mac-inference:image-url ><![CDATA[#[payload.imageURL]]]></mac-inference:image-url>
				</mac-inference:read-image>
				<logger level="INFO" doc:name="Logger" doc:id="67a5c9bf-5609-455c-a0c4-ac447115e5c2" message="default .." />
			</when>
			<otherwise>
				<logger level="INFO" doc:name="Logger" doc:id="78289484-8ca6-45b5-a1f4-cb57f0ed7e95" message="default .."/>
			</otherwise>
		</choice>
		<ee:transform doc:name="Transform Message" doc:id="265a5b8e-6786-452a-b020-072958219ccc">
			<ee:message>
				<ee:set-payload><![CDATA[%dw 2.0
output application/json
---
payload]]></ee:set-payload>
			</ee:message>
		</ee:transform>
		<logger level="INFO" doc:name="Logger" doc:id="0e7318cb-8b1b-4197-89fa-8685bbe3c354" message="#[payload]"/>
	</flow>
</mule>
